IMAGE_NAME = "bento/ubuntu-20.04"

K8S_MINOR_VERSION = "24" 					# 만들어질 vm 이름을 지정하는데 사용
NETWORK_SUB = "192.168.50." 				# 원하는 네트워크 주소 설정
START_IP = 140 								# 시작 IP 주소 설정
POD_CIDR = "10.#{K8S_MINOR_VERSION}.0.0/16" # POD_CIDR 설정

cluster = {
  "master" => { :cpus => 2, :mem => 2048 }, # master node 용량 설정
  "node" => { :cpus => 1, :mem => 1024 }    # worker node 용량 설정
}

NODE_COUNT = 2 # 노드 원하는 수 만큼 설정

VM_GROUP_NAME = "k8s-1.#{K8S_MINOR_VERSION}"
DOCKER_VER = "5:20.10.12~3-0~ubuntu-focal" # 설치할 docker 버전 설정
KUBE_VER = "1.#{K8S_MINOR_VERSION}.2-00"   # 설치할 k8s 버전 설정

Vagrant.configure("2") do |config|
  config.vm.box = IMAGE_NAME

  # Master Node(Control Plane)
  config.vm.define "master", primary: true do |master|
    master.vm.box = IMAGE_NAME
    master.vm.network "private_network", ip: "#{NETWORK_SUB}#{START_IP}"
    master.vm.hostname = "master"
    master.vm.provision "kube", type: "shell", privileged: true, path: "scripts/kube.sh", env: {
      "docker_ver" => "#{DOCKER_VER}",
      "k8s_ver" => "#{KUBE_VER}"
    }
    master.vm.provision "0", type: "shell", preserve_order: true, privileged: true, inline: <<-SHELL
      OUTPUT_FILE=/vagrant/join.sh
      rm -rf /vagrant/join.sh
      rm -rf /vagrant/.kube
      sudo kubeadm init --apiserver-advertise-address=#{NETWORK_SUB}#{START_IP} --pod-network-cidr=#{POD_CIDR} --cri-socket=unix:///run/containerd/containerd.sock
	  # Fixed container runtime to containerd
	  echo "KUBELET_KUBEADM_ARGS=--container-runtime=remote --container-runtime-endpoint=/run/containerd/containerd.sock --cgroup-driver=systemd" | sudo tee /var/lib/kubelet/kubeadm-flags.env
      sudo kubeadm token create --print-join-command > /vagrant/join.sh
      chmod +x $OUTPUT_FILE
      mkdir -p $HOME/.kube
      sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
      sudo chown $(id -u):$(id -g) $HOME/.kube/config
      cp -R $HOME/.kube /vagrant/.kube
      #kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
      kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
      kubectl completion bash >/etc/bash_completion.d/kubect
      echo 'alias k=kubectl' >>~/.bashrc
      echo 'complete -o default -F __start_kubectl k' >>~/.bashrc
    SHELL

    #master.vm.provision "file", preserve_order: true, source: "files", destination: "/tmp"
    #master.vm.provision "3", type: "shell", preserve_order: true, privileged: true, path: "scripts/pv.sh"

    master.vm.provider "virtualbox" do |v|
      v.name = "#{VM_GROUP_NAME}-master"
      v.gui = false
      v.memory = cluster['master'][:mem]
      v.cpus = cluster['master'][:cpus]
      v.customize ["modifyvm", :id, "--groups", "/#{VM_GROUP_NAME}"]
      v.customize ["modifyvm", :id, "--vram", "9"]
    end # end provider
  end

   # Worker Node
  (1..NODE_COUNT).each do |i|
    config.vm.define "node-#{i}" do |node|
      node.vm.box = IMAGE_NAME
      node.vm.network "private_network", ip: "#{NETWORK_SUB}#{i + START_IP}"
      node.vm.hostname = "node-#{i}"
      node.vm.provision "kube", type: "shell", privileged: true, path: "scripts/kube.sh", env: {
        "docker_ver" => "#{DOCKER_VER}",
        "k8s_ver" => "#{KUBE_VER}"
      }
      node.vm.provision "shell-1", type: "shell", privileged: true, inline: <<-SHELL
        sudo /vagrant/join.sh
        sudo systemctl daemon-reload
        sudo systemctl restart kubelet
      SHELL
      node.vm.provision "shell-2", type: "shell", privileged: true, inline: <<-SHELL
        sudo echo 'Environment="KUBELET_EXTRA_ARGS=--node-ip=#{NETWORK_SUB}#{i + START_IP}"' >> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
        sudo systemctl daemon-reload
        sudo systemctl restart kubelet
      SHELL

      node.vm.provider "virtualbox" do |v|
        v.name = "#{VM_GROUP_NAME}-node-#{i}"
        v.gui = false
        v.memory = cluster['node'][:mem]
        v.cpus = cluster['node'][:cpus]
        v.customize ["modifyvm", :id, "--groups", "/#{VM_GROUP_NAME}"]
        v.customize ["modifyvm", :id, "--vram", "9"]
      end # end provider
    end
  end
end
